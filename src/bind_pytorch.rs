use crate::bind_common::{
    find_collapsed_args, is_mut_pointer, parse_exports, parse_string_field, pointer_inner,
    ExportFunc,
};

pub fn generate(json_str: &str, module_stem: &str) -> Result<String, String> {
    let exports = parse_exports(json_str)?;
    let lib_name =
        parse_string_field(json_str, "library").unwrap_or_else(|| format!("{module_stem}.so"));

    let mut out = String::new();
    out.push_str(&format!(
        "\"\"\"{module_stem} — generated by ea bind (PyTorch)\"\"\"\n"
    ));
    out.push_str("import ctypes as _ct\n");
    out.push_str("import torch as _torch\n");
    out.push_str("from pathlib import Path as _Path\n\n");
    out.push_str(&format!(
        "_lib = _ct.CDLL(str(_Path(__file__).with_name(\"{lib_name}\")))\n"
    ));

    for func in &exports {
        emit_argtypes(&mut out, func);
        emit_restype(&mut out, func);
    }
    out.push('\n');

    for func in &exports {
        emit_autograd_class(&mut out, func);
        emit_wrapper(&mut out, func);
        out.push('\n');
    }

    Ok(out)
}

fn emit_argtypes(out: &mut String, func: &ExportFunc) {
    out.push_str(&format!("_lib.{}.argtypes = [", func.name));
    for (i, arg) in func.args.iter().enumerate() {
        if i > 0 {
            out.push_str(", ");
        }
        out.push_str(&ctype_for(&arg.ty));
    }
    out.push_str("]\n");
}

fn emit_restype(out: &mut String, func: &ExportFunc) {
    match &func.return_type {
        Some(ty) => out.push_str(&format!("_lib.{}.restype = {}\n", func.name, ctype_for(ty))),
        None => out.push_str(&format!("_lib.{}.restype = None\n", func.name)),
    }
}

fn emit_autograd_class(out: &mut String, func: &ExportFunc) {
    let collapsed = find_collapsed_args(&func.args);
    let class_name = to_class_name(&func.name);

    out.push_str(&format!("class _{class_name}(_torch.autograd.Function):\n"));
    out.push_str("    @staticmethod\n");

    // Build forward parameter list (non-collapsed, non-length params)
    let mut fwd_params = vec!["ctx".to_string()];
    for (i, arg) in func.args.iter().enumerate() {
        if collapsed[i] {
            continue;
        }
        fwd_params.push(arg.name.clone());
    }

    out.push_str(&format!("    def forward({}):\n", fwd_params.join(", ")));

    // Emit tensor setup for pointer args
    for (i, arg) in func.args.iter().enumerate() {
        if collapsed[i] {
            continue;
        }
        if let Some(_inner) = pointer_inner(&arg.ty) {
            let torch_method = torch_cast_method(_inner);
            if is_mut_pointer(&arg.ty) {
                // Mutable pointer: clone to create output
                out.push_str(&format!(
                    "        {name} = {name}.contiguous().{torch_method}()\n",
                    name = arg.name
                ));
                out.push_str(&format!(
                    "        assert {name}.device.type == \"cpu\", \"Ea kernels run on CPU\"\n",
                    name = arg.name
                ));
                out.push_str(&format!("        _out_{name} = {name}.clone()\n", name = arg.name));
            } else {
                out.push_str(&format!(
                    "        {name} = {name}.contiguous().{torch_method}()\n",
                    name = arg.name
                ));
                out.push_str(&format!(
                    "        assert {name}.device.type == \"cpu\", \"Ea kernels run on CPU\"\n",
                    name = arg.name
                ));
            }
            let _ = torch_dtype; // used in ctype_for already
        }
    }

    // Build call arguments
    let mut call_args = Vec::new();
    let mut last_ptr_arg: Option<&str> = None;
    let mut has_mut_output = false;
    let mut mut_output_name = String::new();
    for (i, arg) in func.args.iter().enumerate() {
        if pointer_inner(&arg.ty).is_some() {
            last_ptr_arg = Some(&arg.name);
            let ptr_ctype = ctype_for(&arg.ty);
            if is_mut_pointer(&arg.ty) {
                has_mut_output = true;
                mut_output_name = arg.name.clone();
                call_args.push(format!(
                    "            _ct.cast(_out_{}.data_ptr(), {ptr_ctype})",
                    arg.name
                ));
            } else {
                call_args.push(format!(
                    "            _ct.cast({}.data_ptr(), {ptr_ctype})",
                    arg.name
                ));
            }
        } else if collapsed[i] {
            let ptr_name = last_ptr_arg.unwrap_or("data");
            call_args.push(format!(
                "            {}({ptr_name}.numel())",
                scalar_ctype(&arg.ty)
            ));
        } else {
            call_args.push(format!(
                "            {}({}({}))",
                scalar_ctype(&arg.ty),
                python_cast(&arg.ty),
                arg.name
            ));
        }
    }

    out.push_str(&format!("        _lib.{}(\n", func.name));
    for (i, ca) in call_args.iter().enumerate() {
        out.push_str(ca);
        if i + 1 < call_args.len() {
            out.push(',');
        }
        out.push('\n');
    }
    out.push_str("        )\n");

    if has_mut_output {
        out.push_str(&format!("        return _out_{mut_output_name}\n"));
    } else if func.return_type.is_some() {
        // If there's a return type but no mut pointer output, we'd need to capture the result
        // For now, re-emit the call with result capture
        // Actually the call above already happened — let's restructure
    }

    out.push('\n');
    out.push_str("    @staticmethod\n");
    out.push_str("    def backward(ctx, grad_output):\n");
    out.push_str("        raise NotImplementedError(\"forward-only — Ea kernels are not differentiable\")\n");
    out.push('\n');
}

fn emit_wrapper(out: &mut String, func: &ExportFunc) {
    let collapsed = find_collapsed_args(&func.args);
    let class_name = to_class_name(&func.name);

    let mut py_params = Vec::new();
    for (i, arg) in func.args.iter().enumerate() {
        if collapsed[i] {
            continue;
        }
        py_params.push(arg.name.clone());
    }

    out.push_str(&format!("def {}({}):\n", func.name, py_params.join(", ")));

    // Docstring showing original C signature
    let c_args: Vec<String> = func
        .args
        .iter()
        .map(|a| format!("{}: {}", a.name, a.ty))
        .collect();
    let c_ret = func.return_type.as_deref().unwrap_or("void");
    out.push_str(&format!(
        "    \"\"\"{}({}) -> {}\"\"\"\n",
        func.name,
        c_args.join(", "),
        c_ret
    ));

    out.push_str(&format!(
        "    return _{class_name}.apply({})\n",
        py_params.join(", ")
    ));
}

fn to_class_name(name: &str) -> String {
    let mut result = String::new();
    let mut capitalize_next = true;
    for c in name.chars() {
        if c == '_' {
            capitalize_next = true;
        } else if capitalize_next {
            result.push(c.to_ascii_uppercase());
            capitalize_next = false;
        } else {
            result.push(c);
        }
    }
    result
}

fn ctype_for(ty: &str) -> String {
    if let Some(inner) = pointer_inner(ty) {
        return format!("_ct.POINTER({})", scalar_ctype(inner));
    }
    scalar_ctype(ty)
}

fn scalar_ctype(ty: &str) -> String {
    match ty {
        "i8" => "_ct.c_int8".into(),
        "u8" => "_ct.c_uint8".into(),
        "i16" => "_ct.c_int16".into(),
        "u16" => "_ct.c_uint16".into(),
        "i32" => "_ct.c_int32".into(),
        "u32" => "_ct.c_uint32".into(),
        "i64" => "_ct.c_int64".into(),
        "u64" => "_ct.c_uint64".into(),
        "f32" => "_ct.c_float".into(),
        "f64" => "_ct.c_double".into(),
        "bool" => "_ct.c_bool".into(),
        other => format!("_ct.c_int32 /* unknown: {other} */"),
    }
}

fn torch_dtype(ty: &str) -> &'static str {
    match ty {
        "f32" => "torch.float32",
        "f64" => "torch.float64",
        "i8" => "torch.int8",
        "u8" => "torch.uint8",
        "i16" => "torch.int16",
        "i32" => "torch.int32",
        "i64" => "torch.int64",
        _ => "torch.float32",
    }
}

fn torch_cast_method(ty: &str) -> &'static str {
    match ty {
        "f32" => "float",
        "f64" => "double",
        "i8" => "char",
        "u8" => "byte",
        "i16" => "short",
        "i32" => "int",
        "i64" => "long",
        _ => "float",
    }
}

fn python_cast(ty: &str) -> &'static str {
    match ty {
        "f32" | "f64" => "float",
        "bool" => "bool",
        _ => "int",
    }
}
